# Songbird: A Deep Learning Approach for Jazz/Blues Generation

## Overview

**Songbird** is a student project from the Spring 2025 Deep Learning course. It explores deep learning-based symbolic music generation, focusing on expressive jazz and blues using autoregressive Transformer models. The model takes MIDI-based note sequences and produces stylistically rich, polyphonic jazz compositions. We also incorporated reinforcement learning (REINFORCE) to improve musicality.

## Key Features

* Autoregressive Transformer-based architecture
* Reinforcement Learning (REINFORCE) for musical refinement
* Polyphonic output with support for chords, rests, rhythm
* PyTorch + TensorFlow dual implementations for experimentation
* Music tokenization pipeline (pitch + duration)

## Project Architecture

The model generates music in an autoregressive way, one token at a time. Each token encodes both pitch and rhythmic duration (e.g., `C4_0.25`). After supervised training, Songbird is further optimized using Monte Carlo REINFORCE to maximize custom musical reward functions:

* Harmonic Consistency
* Melodic Contour
* Rhythm Diversity
* Interval Quality

## Dataset & Preprocessing

* **Source**: Jazz MIDI collections including "Jazz ML ready MIDI" and curated files (e.g., Doug McKenzie's piano transcriptions)
* **Token Format**: `{pitch}_{duration}` (e.g., `C4_1.0`, `C4.E4.G4_0.5`)
* **Cleaning**: Filtered out unsuitable tracks, removed invalid durations, kept single-instrument melodies
* **Training Data**: Converted to token sequences of length 100 for input-output prediction pairs

## Evaluation Metrics

* **Training/Testing Loss**: Cross-entropy loss on next-token prediction
* **Human Feedback**: Early-stage subjective evaluation for musicality
* **Reward Functions (RL phase)**:

  * Interval quality score
  * Harmonic consistency
  * Rhythm diversity
  * Melodic contour score

## File Structure

```
songbird-main/
├── jazz_and_stuff.zip              # Collection of jazz MIDI files
├── rl_best.h5                      # Saved weights after RL fine-tuning
├── iters/                          # MIDI files generated by the model
│   └── *.mid
├── src/
│   ├── main.ipynb                  # Summary of experiments
│   └── armstrong-build/
│       ├── arm.sh / gen.sh         # Shell scripts for training and generation
│       ├── train_armstrong.py      # Supervised training code
│       ├── gen_armstrong.py        # MIDI generation code
│       ├── monk_lambda.py          # TensorFlow + RL Transformer (monk)
│       ├── monk_torch.py           # PyTorch version of Transformer
│       └── jazz_and_stuff/         # Expanded MIDI dataset
```

## How to Run

You can run the project using any Ubuntu terminal.

1. Make sure `jazz_and_stuff.zip` is unzipped in the correct directory.
2. Run the model with supervised or RL-based Transformer by modifying the script:

```bash
bash monk_docker.sh
```

3. To switch between **supervised** and **reinforcement learning** versions:

* Edit `monk_docker.sh` to call either `monk_lambda.py` or `monk_lambda_new.py`

  * `monk_lambda.py` = baseline Transformer (no RL)
  * `monk_lambda_new.py` = RL fine-tuned Transformer (with REINFORCE)

4. To run training and generation separately:

```bash
bash arm.sh         # Train the model
bash gen.sh         # Generate jazz samples
```

## Contributions

| Name          | Task                                                                                        | Files                               | Lines     |
| ------------- | ------------------------------------------------------------------------------------------- | ----------------------------------- | --------- |
| Sadman Kabir  | LSTM + Transformer v1, full tokenization, REINFORCE fine-tuning                             | ModelA.py                           | \~300     |
| Chen Han Lin  | Transformer v1, preprocessing, dataset curation, training                                   | Processdata.py, ModelB.py           | \~400     |
| Xushuai Zhang | Trained all models, implemented monk Transformer (RL+Torch), wrote shell & PyTorch versions | monk\_lambda.py, monk\_torch.py, sh | \~300–400 |

## GitHub

[https://github.com/corndog-overflow/songbird](https://github.com/corndog-overflow/songbird)

## Dependencies

* Python 3.x
* PyTorch or TensorFlow
* music21
* pretty\_midi
* numpy, argparse

## License

For academic use only. Developed as part of BU’s Spring 2025 Deep Learning course.
